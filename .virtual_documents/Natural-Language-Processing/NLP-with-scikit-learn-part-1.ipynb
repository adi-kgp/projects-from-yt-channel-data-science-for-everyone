


import nltk


nltk.download()


# SMS spam dataset
!head sms+spam+collection/SMSSpamCollection


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


df = pd.read_csv("SMSSpamCollection", sep="\t", names=["label", "text"])


df.head()





df.describe()


df.groupby("label").describe()


sns.countplot(data=df, x="label");





df['text'][0], len(df['text'][0])


df['length'] = df['text'].apply(len)


df.head()


sns.displot(df["length"], bins=50);


df['length'].describe()


df[df['length'] == 910]['text'].iloc[0]


df[df['length'] == 2]['text'].iloc[0]


df.hist(column="length", by="label", bins=50, figsize=(12,6))
plt.show()





from nltk.corpus import stopwords
import string


stopwords.words("english")[1:20]


len(stopwords.words("english"))


string.punctuation


def text_processing(text):
    # remove punctuation
    remove_punc = [c for c in text if c not in string.punctuation]
    # Join punc together
    remove_punc = ''.join(remove_punc)
    # remove stopwords
    return [w for w in remove_punc.split() if w.lower() not in stopwords.words('english')]


df.head()


df['text'].apply(text_processing)





from sklearn.feature_extraction.text import CountVectorizer


cv_transformer = CountVectorizer(analyzer=text_processing).fit(df['text'])


len(cv_transformer.vocabulary_)


text_0 = df['text'][2]
text_0


bow_0 = cv_transformer.transform([text_0])
bow_0


print(bow_0)


print(bow_0.shape)


df['text'][2]


cv_transformer.get_feature_names_out()[6331], cv_transformer.get_feature_names_out()[1833]


text_messages_bow = cv_transformer.transform(df['text'])


print(f"Shape of the Sparse Matrix: {text_messages_bow.shape}")
print(f"Amount of Non-Zero Occurences: {text_messages_bow.nnz}")


sparcity = text_messages_bow.nnz / (text_messages_bow.shape[0] * text_messages_bow.shape[1])*100


print(f"Sparcity: {sparcity}")





from sklearn.feature_extraction.text import TfidfTransformer


tfidf_transformer = TfidfTransformer().fit(text_messages_bow)


tfidf_0 = tfidf_transformer.transform(bow_0)


print(tfidf_0)


cv_transformer.get_feature_names_out()[423]


print(tfidf_transformer.idf_[cv_transformer.vocabulary_['think']])


text_tfidf = tfidf_transformer.transform(text_messages_bow)


text_tfidf.shape








from sklearn.naive_bayes import MultinomialNB


nb = MultinomialNB().fit(text_tfidf, df['label'])


print(tfidf_0[0])


text_0


pred = nb.predict(tfidf_0)[0]


expected = df['label'][2]
print(f"Predicted Value: {pred}\nExpected Value: {expected}")





all_predictions = nb.predict(text_tfidf)


all_predictions


from sklearn.metrics import classification_report


print(classification_report(df['label'], all_predictions))





from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.33, random_state=42)





from sklearn.pipeline import Pipeline


pipeline = Pipeline([
    ('bow', CountVectorizer(analyzer=text_processing)), # strings to tokens
    ('tfidf', TfidfTransformer()), # Tf-idf scores
    ('classifier', MultinomialNB()) # Train model using TF-IDF with NB
])


pipeline.fit(X_train, y_train)












